{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HJJoosse/ws-julia-nov22/blob/main/Workshop_Julia_Skyline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# Workshop Julia \n",
        "\n",
        "Following is a standard Julia template for installing Julia on Colab, please follow the instructions (we don't necessarily need a GPU for this workshop). However, if you feel like it, please feel free to use one.\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIeFXS0F0zww",
        "outputId": "1a3c1e31-43ee-440b-b0ac-676cc9afc4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.8.2 on the current Colab Runtime...\n",
            "2022-10-31 14:12:25 URL:https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.2-linux-x86_64.tar.gz [135859273/135859273] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package UrlDownload...\n",
            "Installing Julia package Plots...\n",
            "Installing Julia package Distributions...\n",
            "Installing Julia package CSV...\n",
            "Installing Julia package DataFrames...\n",
            "Installing Julia package MLJ...\n",
            "Installing Julia package XGBoost...\n",
            "Installing Julia package MLJLinearModels...\n",
            "Installing Julia package MLJXGBoostInterface...\n",
            "Installing Julia package MLJModels...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.8\n",
            "\n",
            "Successfully installed julia version 1.8.2!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia UrlDownload Plots Distributions CSV DataFrames MLJ XGBoost MLJLinearModels MLJXGBoostInterface MLJModels\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEzvvzCl1i0F",
        "outputId": "3da12ef8-5846-4f20-e298-533020a8c3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.8.2\n",
            "Commit 36034abf260 (2022-09-29 15:21 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-linux-gnu)\n",
            "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-13.0.1 (ORCJIT, broadwell)\n",
            "  Threads: 2 on 2 virtual cores\n",
            "Environment:\n",
            "  LD_LIBRARY_PATH = /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "  LD_PRELOAD = /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ],
      "source": [
        "versioninfo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvCHra-2jvnK"
      },
      "source": [
        "### Using Julia\n",
        "\n",
        "Let's first take a look at how Julia functions. Variable naming is very similar to R and Python. We can just assign a value to a certain name, and you're done.\n",
        "We can, however, also use unicode! This latter is also very useful, as we can use the ∉ or ∈ variable for subsetting. But for this workshop, as we work in Colab, we will not be using this. \n",
        "Another neat item is list comprehensions, which work more or less the same as in Python. If else statements in these comprehensions work a bit differently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfMGJPq0jsEQ",
        "outputId": "0506cebf-082d-432f-8e17-486a05f623b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3-element Vector{Int64}:\n",
              " 1\n",
              " 0\n",
              " 1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [1,2,3];\n",
        "b = \"Hi!\"\n",
        "c = [3,4,5]\n",
        "d = [x for x in a if x in c] ### get all the items that are in a and c (basically the intersection)\n",
        "e = [x-2 < 0 ? abs(x-2) : x-2 for x in a] ### if x-2 < 0 then abs(x-2) else x-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5PCPHKhOfEd"
      },
      "source": [
        "When working with lists, arrays and other iterables, there are some differences compared to R and Python. For example, when trying to do an operation over an iterable, we use . in front of the operator, or behind the function call. For example, lets assume we have an array, and we want to select all the items above a certain value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhoUGQ3tOdLX",
        "outputId": "425c2ca8-91c0-4310-c016-24c9eda6ae63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50-element Vector{Float64}:\n",
              " -0.4026044217331692\n",
              " -0.7579234775692633\n",
              " -0.7972294988994\n",
              " -0.7664814396566303\n",
              " -0.3771328531213684\n",
              " -0.13903512398461848\n",
              " -0.32440620960932315\n",
              " -0.9218759209954368\n",
              " -0.234877665918437\n",
              " -0.5137123051152007\n",
              " -0.34948578125480073\n",
              " -1.2468521122451373\n",
              " -0.7146517465875762\n",
              "  ⋮\n",
              " -1.0256917532422523\n",
              " -0.23339669338082206\n",
              " -0.23705460547947882\n",
              " -1.5517569081705744\n",
              " -1.4512555781232714\n",
              " -1.4272022248506113\n",
              " -0.8441352051225514\n",
              " -0.9437904937903032\n",
              " -0.28175121867311026\n",
              " -0.8783907343429743\n",
              " -0.2836296162765255\n",
              " -0.5748288490754441"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "using Distributions\n",
        "\n",
        "d = Normal(0,1)\n",
        "x = rand(d, 100)\n",
        "x[x .< 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny2CyrFbQ64X"
      },
      "source": [
        "Or if we have a nested list, and we want a sum of each list within the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXhvUh0IQyyK",
        "outputId": "01999927-801f-4005-e760-345e9cfc39d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2-element Vector{Int64}:\n",
              " 5\n",
              " 9"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [[2,3],[4,5]]\n",
        "sum.(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZma54rDTh17"
      },
      "source": [
        "Matrices can be built quite easily. If we want a column or rowwise sum, we have to use the ```eachcol``` or ```eachrow``` command.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZroZM5-WTmWL",
        "outputId": "e34716b0-72db-4d51-ee96-617eb21e32a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2-element Vector{Int64}:\n",
              " 4\n",
              " 6"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = [1 2;3 4]\n",
        "sum(eachrow(A))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jKwhr-WYmL5"
      },
      "source": [
        "One last syntactic thing I would like to discuss is the (...) syntax, which is the syntax for splatting in Julia. We might know splatting from Python where we can use * (e.g., ```print(*a)```, which would result in ```1 2 3``` instead of ```[1, 2, 3]```. In Julia we would do the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4saLekkYdI0",
        "outputId": "6c0e91b3-0874-423e-fb86-139906bf48f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3]\n",
            "123"
          ]
        }
      ],
      "source": [
        "a = [1,2,3];\n",
        "println(a)\n",
        "print(a...)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reuhPAnydjhH"
      },
      "source": [
        "### Let's Get Started!\n",
        "\n",
        "In this tutorial we will work with the [the Winconsin Breast Cancer Data](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)).\n",
        "\n",
        "Go ahead and download the data using the URLDownload package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z-i26ptwdypb"
      },
      "outputs": [],
      "source": [
        "using UrlDownload, DataFrames, MLJ\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\";\n",
        "feature_names = [\"ID\", \"Class\", \"mean_radius\", \"mean_texture\", \"mean_perimeter\",\n",
        " \"mean_area\", \"mean_smoothness\", \"mean_compactness\", \"mean_concavity\", \"mean_concave_points\",\n",
        "  \"mean_symmetry\", \"mean_fractal_dimension\", \"radius_error\", \"texture_error\", \"perimeter_error\", \"area_error\",\n",
        "   \"smoothness_error\", \"compactness_error\", \"concavity_error\", \"concave_points_error\", \"symmetry_error\", \"fractal_dimension error\",\n",
        "    \"worst_adius\", \"worst_texture\", \"worst_perimeter\", \"worst_area\", \"worst_smoothness\", \"worst_compactness\", \"worst_concavity\",\n",
        "     \"worst_concave_points\", \"worst_symmetry\", \"worst_fractal_dimension\"]\n",
        "data = urldownload(url, true, format = :CSV, header = feature_names) |> DataFrame;\n",
        "\n",
        "data = coerce(data,autotype(data));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4mFvs1Y23pb"
      },
      "source": [
        "We already see some more syntactic features of Julia in this code. \n",
        "First of all, when importing modules, there are  two ways of doing this: We can use ```using```, or ```import```. More information on the differences between the two can be found in [the documentation](https://docs.julialang.org/en/v1/manual/modules/#Standalone-using-and-import). TLDR: ```using``` is most commonly used, but ```import``` might be useful for extending on specific functions you import, as this is more limited with ```using```.\n",
        "\n",
        "In the ``` urldownload  ``` call, we see the ``` :CSV ``` argument, which means that the data is loaded into the format as used in the \"CSV\" module. The colon in front of \"CSV\" is a replacement for quotation marks, meaning that this is a symbol.\n",
        "\n",
        "Another syntactic feature that we see is in the ```|>``` operator. This might be familiar from other programming languages, and this is nothing more than a pipe. We could also have called ```DataFrame(urldownload(...))```, which would resulted in the same dataframe.\n",
        "\n",
        "Lastly, we add a semicolon (;) to the end of each sentence, as Julia will output the last call automatically to the output (even if this call would result in a new object).\n",
        "\n",
        "### Indexing rows and columns\n",
        "\n",
        "DataFrame rows and columns are accessed similarly to R and Pandas/Numpy in Python. Important: when accessing Columns, you have to include \":\" to select all rows (e.g., ```df[:,:column_of_interest]```). Columns can also be accessed by using ```df.column_of_interest``` (just like in Pandas). If you want to access more columns, you will have to add a list  ```df[:,[:col1,:col2]]. Another neat trick is to use the ```end``` operator. If we want to select row 2 untill the end we would simply use ```df[2:end,:]``` \n",
        "\n",
        "Try to play around, and select some individual or ranges of rows and columns based on numbers, or based on a certain condition. Also, try to get some summary statistics on some of the columns. Remember: dataframes usually have similar behaviour to matrices, so use the ```eachrow``` and ```eachcol``` functions, or select columns individually, and use the . operator for wrangling and conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3_dq8ksZct_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzGca0e9Q1lf"
      },
      "source": [
        "\n",
        "### Visualization\n",
        "Next, let's inspect what we are working with! We can visualize the outcome (class), to get some intuition for the outcome and data. For this we use the ```Plots``` module. The neat thing about this module is that it is capable of using several backends for plotting. It has a default backend ```GR```, but it is also capable of using ```Plotly``` or ```PyPlot```, amongst others.\n",
        "\n",
        "In this workshop we use the ```Gr``` backend, but feel free to play around with some other backends. A list can be found [here](https://docs.juliaplots.org/latest/backends/).\n",
        "First, let's install the ```StatsPlots``` module, by using the Julia package manager (Pkg), to be able to plot data directly from a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kws5GV0NGorM",
        "outputId": "b6f4fb69-e520-4378-bf5b-6505e2999c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FFTW ────────────── v1.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IntelOpenMP_jll ─── v2018.0.3+2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsPlots ──────── v0.15.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Ratios ──────────── v0.4.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OffsetArrays ────── v1.12.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MKL_jll ─────────── v2022.2.0+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataValues ──────── v0.4.13\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighbors ── v0.4.12\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m KernelDensity ───── v0.6.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Clustering ──────── v0.14.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AbstractFFTs ────── v1.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FFTW_jll ────────── v3.3.10+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Adapt ───────────── v3.4.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Widgets ─────────── v0.6.6\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MultivariateStats ─ v0.10.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Arpack_jll ──────── v3.5.1+1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TableOperations ─── v1.2.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AxisAlgorithms ──── v1.0.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Arpack ──────────── v0.5.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m WoodburyMatrices ── v0.5.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Observables ─────── v0.5.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Interpolations ──── v0.14.6\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
            " \u001b[90m [f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.4\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Manifest.toml`\n",
            " \u001b[90m [621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.2.1\u001b[39m\n",
            " \u001b[90m [79e6a3ab] \u001b[39m\u001b[92m+ Adapt v3.4.0\u001b[39m\n",
            " \u001b[90m [7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.5.3\u001b[39m\n",
            " \u001b[90m [13072b0f] \u001b[39m\u001b[92m+ AxisAlgorithms v1.0.1\u001b[39m\n",
            " \u001b[90m [aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.14.3\u001b[39m\n",
            " \u001b[90m [e7dc6d0d] \u001b[39m\u001b[92m+ DataValues v0.4.13\u001b[39m\n",
            " \u001b[90m [7a1cc6ca] \u001b[39m\u001b[92m+ FFTW v1.5.0\u001b[39m\n",
            " \u001b[90m [a98d9a8b] \u001b[39m\u001b[92m+ Interpolations v0.14.6\u001b[39m\n",
            " \u001b[90m [5ab0869b] \u001b[39m\u001b[92m+ KernelDensity v0.6.5\u001b[39m\n",
            " \u001b[90m [6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.0\u001b[39m\n",
            " \u001b[90m [b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.12\u001b[39m\n",
            " \u001b[90m [510215fc] \u001b[39m\u001b[92m+ Observables v0.5.2\u001b[39m\n",
            " \u001b[90m [6fe1bfb0] \u001b[39m\u001b[92m+ OffsetArrays v1.12.8\u001b[39m\n",
            " \u001b[90m [c84ed2f1] \u001b[39m\u001b[92m+ Ratios v0.4.3\u001b[39m\n",
            " \u001b[90m [f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.4\u001b[39m\n",
            " \u001b[90m [ab02a1b2] \u001b[39m\u001b[92m+ TableOperations v1.2.0\u001b[39m\n",
            " \u001b[90m [cc8bc4a8] \u001b[39m\u001b[92m+ Widgets v0.6.6\u001b[39m\n",
            " \u001b[90m [efce3f68] \u001b[39m\u001b[92m+ WoodburyMatrices v0.5.5\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m\u001b[90m [68821587] \u001b[39m\u001b[92m+ Arpack_jll v3.5.1+1\u001b[39m\n",
            " \u001b[90m [f5851436] \u001b[39m\u001b[92m+ FFTW_jll v3.3.10+0\u001b[39m\n",
            " \u001b[90m [1d5cc7b8] \u001b[39m\u001b[92m+ IntelOpenMP_jll v2018.0.3+2\u001b[39m\n",
            " \u001b[90m [856f044c] \u001b[39m\u001b[92m+ MKL_jll v2022.2.0+0\u001b[39m\n",
            " \u001b[90m [4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts\u001b[39m\n",
            " \u001b[90m [1a1011a3] \u001b[39m\u001b[92m+ SharedArrays\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mWoodburyMatrices\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mObservables\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mRatios\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mIntelOpenMP_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDataValues\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mArpack_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAxisAlgorithms\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mTableOperations\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOffsetArrays\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mWidgets\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMKL_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mArpack\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mClustering\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMultivariateStats\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mKernelDensity\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mStatsPlots\n",
            "  22 dependencies successfully precompiled in 36 seconds. 221 already precompiled.\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.add(\"StatsPlots\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMPgaGDcBklk"
      },
      "source": [
        "We then import the ```Plots``` module, and call the ```GR``` backend with the ```gr()``` call. The last part is optional, as GR is the default backend. But if one would plotly or pyplot or other backends, this step would be how you set the backend. Then we a histogram of the outcome class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWK_c3RtDjxA",
        "outputId": "2102bba2-e020-4bbf-d7e2-06601e17de2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Plots.GRBackend()"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "using Plots, StatsPlots\n",
        "gr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3GeQtdKQCAy"
      },
      "source": [
        "```Statsplot``` makes it possible to use the ```@df``` operator, which makes it easy to use a dataframe. The syntax would be: ```@df dataframe_name plot_type(:column1, :column2)```. But you can also use ```histogram(data[:,:Class])```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "BHUgjcAdFuhz",
        "outputId": "0b1c030d-fbb7-482e-f681-20e099bbb9f9"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip770\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip770)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip771\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip770)\" d=\"\nM109.747 1486.45 L2352.76 1486.45 L2352.76 47.2441 L109.747 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip772\">\n    <rect x=\"109\" y=\"47\" width=\"2244\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  565.828,1486.45 565.828,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1064.9,1486.45 1064.9,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1563.96,1486.45 1563.96,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2063.03,1486.45 2063.03,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  109.747,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  565.828,1486.45 565.828,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1064.9,1486.45 1064.9,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1563.96,1486.45 1563.96,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2063.03,1486.45 2063.03,1467.55 \n  \"/>\n<path clip-path=\"url(#clip770)\" d=\"M533.779 1544.91 L541.418 1544.91 L541.418 1518.55 L533.108 1520.21 L533.108 1515.95 L541.372 1514.29 L546.048 1514.29 L546.048 1544.91 L553.687 1544.91 L553.687 1548.85 L533.779 1548.85 L533.779 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M563.131 1542.97 L568.015 1542.97 L568.015 1548.85 L563.131 1548.85 L563.131 1542.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M582.228 1544.91 L598.548 1544.91 L598.548 1548.85 L576.603 1548.85 L576.603 1544.91 Q579.265 1542.16 583.849 1537.53 Q588.455 1532.88 589.636 1531.53 Q591.881 1529.01 592.761 1527.27 Q593.663 1525.51 593.663 1523.82 Q593.663 1521.07 591.719 1519.33 Q589.798 1517.6 586.696 1517.6 Q584.497 1517.6 582.043 1518.36 Q579.612 1519.13 576.835 1520.68 L576.835 1515.95 Q579.659 1514.82 582.112 1514.24 Q584.566 1513.66 586.603 1513.66 Q591.974 1513.66 595.168 1516.35 Q598.362 1519.03 598.362 1523.52 Q598.362 1525.65 597.552 1527.57 Q596.765 1529.47 594.659 1532.07 Q594.08 1532.74 590.978 1535.95 Q587.876 1539.15 582.228 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1032.55 1544.91 L1040.18 1544.91 L1040.18 1518.55 L1031.87 1520.21 L1031.87 1515.95 L1040.14 1514.29 L1044.81 1514.29 L1044.81 1544.91 L1052.45 1544.91 L1052.45 1548.85 L1032.55 1548.85 L1032.55 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1061.9 1542.97 L1066.78 1542.97 L1066.78 1548.85 L1061.9 1548.85 L1061.9 1542.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1077.01 1514.29 L1095.37 1514.29 L1095.37 1518.22 L1081.3 1518.22 L1081.3 1526.7 Q1082.31 1526.35 1083.33 1526.19 Q1084.35 1526 1085.37 1526 Q1091.16 1526 1094.54 1529.17 Q1097.92 1532.34 1097.92 1537.76 Q1097.92 1543.34 1094.44 1546.44 Q1090.97 1549.52 1084.65 1549.52 Q1082.48 1549.52 1080.21 1549.15 Q1077.96 1548.78 1075.56 1548.04 L1075.56 1543.34 Q1077.64 1544.47 1079.86 1545.03 Q1082.08 1545.58 1084.56 1545.58 Q1088.56 1545.58 1090.9 1543.48 Q1093.24 1541.37 1093.24 1537.76 Q1093.24 1534.15 1090.9 1532.04 Q1088.56 1529.94 1084.56 1529.94 Q1082.68 1529.94 1080.81 1530.35 Q1078.96 1530.77 1077.01 1531.65 L1077.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1531.16 1544.91 L1538.8 1544.91 L1538.8 1518.55 L1530.49 1520.21 L1530.49 1515.95 L1538.75 1514.29 L1543.43 1514.29 L1543.43 1544.91 L1551.07 1544.91 L1551.07 1548.85 L1531.16 1548.85 L1531.16 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1560.51 1542.97 L1565.4 1542.97 L1565.4 1548.85 L1560.51 1548.85 L1560.51 1542.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1585.58 1532.44 Q1582.25 1532.44 1580.33 1534.22 Q1578.43 1536 1578.43 1539.13 Q1578.43 1542.25 1580.33 1544.03 Q1582.25 1545.82 1585.58 1545.82 Q1588.92 1545.82 1590.84 1544.03 Q1592.76 1542.23 1592.76 1539.13 Q1592.76 1536 1590.84 1534.22 Q1588.94 1532.44 1585.58 1532.44 M1580.91 1530.45 Q1577.9 1529.7 1576.21 1527.64 Q1574.54 1525.58 1574.54 1522.62 Q1574.54 1518.48 1577.48 1516.07 Q1580.44 1513.66 1585.58 1513.66 Q1590.75 1513.66 1593.69 1516.07 Q1596.62 1518.48 1596.62 1522.62 Q1596.62 1525.58 1594.94 1527.64 Q1593.27 1529.7 1590.28 1530.45 Q1593.66 1531.23 1595.54 1533.52 Q1597.44 1535.82 1597.44 1539.13 Q1597.44 1544.15 1594.36 1546.83 Q1591.3 1549.52 1585.58 1549.52 Q1579.87 1549.52 1576.79 1546.83 Q1573.73 1544.15 1573.73 1539.13 Q1573.73 1535.82 1575.63 1533.52 Q1577.53 1531.23 1580.91 1530.45 M1579.19 1523.06 Q1579.19 1525.75 1580.86 1527.25 Q1582.55 1528.76 1585.58 1528.76 Q1588.59 1528.76 1590.28 1527.25 Q1592 1525.75 1592 1523.06 Q1592 1520.38 1590.28 1518.87 Q1588.59 1517.37 1585.58 1517.37 Q1582.55 1517.37 1580.86 1518.87 Q1579.19 1520.38 1579.19 1523.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2034.88 1544.91 L2051.2 1544.91 L2051.2 1548.85 L2029.26 1548.85 L2029.26 1544.91 Q2031.92 1542.16 2036.5 1537.53 Q2041.11 1532.88 2042.29 1531.53 Q2044.54 1529.01 2045.41 1527.27 Q2046.32 1525.51 2046.32 1523.82 Q2046.32 1521.07 2044.37 1519.33 Q2042.45 1517.6 2039.35 1517.6 Q2037.15 1517.6 2034.7 1518.36 Q2032.27 1519.13 2029.49 1520.68 L2029.49 1515.95 Q2032.31 1514.82 2034.77 1514.24 Q2037.22 1513.66 2039.26 1513.66 Q2044.63 1513.66 2047.82 1516.35 Q2051.02 1519.03 2051.02 1523.52 Q2051.02 1525.65 2050.21 1527.57 Q2049.42 1529.47 2047.31 1532.07 Q2046.73 1532.74 2043.63 1535.95 Q2040.53 1539.15 2034.88 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2061.02 1542.97 L2065.9 1542.97 L2065.9 1548.85 L2061.02 1548.85 L2061.02 1542.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2076.9 1544.91 L2084.54 1544.91 L2084.54 1518.55 L2076.22 1520.21 L2076.22 1515.95 L2084.49 1514.29 L2089.16 1514.29 L2089.16 1544.91 L2096.8 1544.91 L2096.8 1548.85 L2076.9 1548.85 L2076.9 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  109.747,1441.91 2352.76,1441.91 \n  \"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  109.747,1438.11 2352.76,1438.11 \n  \"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  109.747,1434.31 2352.76,1434.31 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  109.747,1486.45 109.747,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  109.747,1441.91 128.644,1441.91 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  109.747,1438.11 128.644,1438.11 \n  \"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  109.747,1434.31 128.644,1434.31 \n  \"/>\n<path clip-path=\"url(#clip770)\" d=\"M53.8393 1455.26 L61.4782 1455.26 L61.4782 1428.89 L53.168 1430.56 L53.168 1426.3 L61.4319 1424.63 L66.1078 1424.63 L66.1078 1455.26 L73.7466 1455.26 L73.7466 1459.19 L53.8393 1459.19 L53.8393 1455.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M57.4273 1451.45 L73.7466 1451.45 L73.7466 1455.39 L51.8023 1455.39 L51.8023 1451.45 Q54.4643 1448.7 59.0476 1444.07 Q63.6541 1439.42 64.8346 1438.07 Q67.08 1435.55 67.9596 1433.82 Q68.8624 1432.06 68.8624 1430.37 Q68.8624 1427.61 66.918 1425.88 Q64.9967 1424.14 61.8948 1424.14 Q59.6958 1424.14 57.2421 1424.9 Q54.8115 1425.67 52.0338 1427.22 L52.0338 1422.5 Q54.8578 1421.36 57.3115 1420.78 Q59.7652 1420.2 61.8023 1420.2 Q67.1726 1420.2 70.367 1422.89 Q73.5614 1425.57 73.5614 1430.07 Q73.5614 1432.19 72.7513 1434.12 Q71.9642 1436.01 69.8578 1438.61 Q69.2791 1439.28 66.1772 1442.5 Q63.0754 1445.69 57.4273 1451.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M66.617 1432.95 Q69.9735 1433.67 71.8485 1435.94 Q73.7466 1438.21 73.7466 1441.54 Q73.7466 1446.66 70.2281 1449.46 Q66.7096 1452.26 60.2282 1452.26 Q58.0523 1452.26 55.7375 1451.82 Q53.4458 1451.4 50.9921 1450.54 L50.9921 1446.03 Q52.9366 1447.16 55.2514 1447.74 Q57.5662 1448.32 60.0893 1448.32 Q64.4874 1448.32 66.7791 1446.59 Q69.0939 1444.85 69.0939 1441.54 Q69.0939 1438.48 66.9411 1436.77 Q64.8115 1435.04 60.9921 1435.04 L56.9643 1435.04 L56.9643 1431.19 L61.1773 1431.19 Q64.6263 1431.19 66.455 1429.83 Q68.2837 1428.44 68.2837 1425.85 Q68.2837 1423.18 66.3856 1421.77 Q64.5106 1420.34 60.9921 1420.34 Q59.0708 1420.34 56.8717 1420.75 Q54.6727 1421.17 52.0338 1422.05 L52.0338 1417.88 Q54.6958 1417.14 57.0106 1416.77 Q59.3486 1416.4 61.4087 1416.4 Q66.7328 1416.4 69.8346 1418.83 Q72.9365 1421.24 72.9365 1425.36 Q72.9365 1428.23 71.2929 1430.22 Q69.6494 1432.19 66.617 1432.95 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip772)\" d=\"\nM233.116 87.9763 L233.116 1445.72 L565.828 1445.72 L565.828 87.9763 L233.116 87.9763 L233.116 87.9763  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  233.116,87.9763 233.116,1445.72 565.828,1445.72 565.828,87.9763 233.116,87.9763 \n  \"/>\n<path clip-path=\"url(#clip772)\" d=\"\nM565.828 1445.72 L565.828 1445.72 L898.54 1445.72 L898.54 1445.72 L565.828 1445.72 L565.828 1445.72  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  565.828,1445.72 565.828,1445.72 898.54,1445.72 565.828,1445.72 \n  \"/>\n<path clip-path=\"url(#clip772)\" d=\"\nM898.54 1445.72 L898.54 1445.72 L1231.25 1445.72 L1231.25 1445.72 L898.54 1445.72 L898.54 1445.72  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  898.54,1445.72 898.54,1445.72 1231.25,1445.72 898.54,1445.72 \n  \"/>\n<path clip-path=\"url(#clip772)\" d=\"\nM1231.25 1445.72 L1231.25 1445.72 L1563.96 1445.72 L1563.96 1445.72 L1231.25 1445.72 L1231.25 1445.72  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1231.25,1445.72 1231.25,1445.72 1563.96,1445.72 1231.25,1445.72 \n  \"/>\n<path clip-path=\"url(#clip772)\" d=\"\nM1563.96 1445.72 L1563.96 1445.72 L1896.67 1445.72 L1896.67 1445.72 L1563.96 1445.72 L1563.96 1445.72  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1563.96,1445.72 1563.96,1445.72 1896.67,1445.72 1563.96,1445.72 \n  \"/>\n<path clip-path=\"url(#clip772)\" d=\"\nM1896.67 639.439 L1896.67 1445.72 L2229.39 1445.72 L2229.39 639.439 L1896.67 639.439 L1896.67 639.439  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1896.67,639.439 1896.67,1445.72 2229.39,1445.72 2229.39,639.439 1896.67,639.439 \n  \"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"399.472\" cy=\"87.9763\" r=\"2\"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"732.184\" cy=\"1445.72\" r=\"2\"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1064.9\" cy=\"1445.72\" r=\"2\"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1397.61\" cy=\"1445.72\" r=\"2\"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1730.32\" cy=\"1445.72\" r=\"2\"/>\n<circle clip-path=\"url(#clip772)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2063.03\" cy=\"639.439\" r=\"2\"/>\n<path clip-path=\"url(#clip770)\" d=\"\nM1976.34 198.898 L2277.99 198.898 L2277.99 95.2176 L1976.34 95.2176  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1976.34,198.898 2277.99,198.898 2277.99,95.2176 1976.34,95.2176 1976.34,198.898 \n  \"/>\n<path clip-path=\"url(#clip770)\" d=\"\nM2001.26 167.794 L2150.79 167.794 L2150.79 126.322 L2001.26 126.322 L2001.26 167.794  Z\n  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2001.26,167.794 2150.79,167.794 2150.79,126.322 2001.26,126.322 2001.26,167.794 \n  \"/>\n<path clip-path=\"url(#clip770)\" d=\"M2189.56 166.745 Q2187.75 171.375 2186.04 172.787 Q2184.33 174.199 2181.45 174.199 L2178.05 174.199 L2178.05 170.634 L2180.55 170.634 Q2182.31 170.634 2183.28 169.8 Q2184.26 168.967 2185.44 165.865 L2186.2 163.921 L2175.71 138.412 L2180.23 138.412 L2188.33 158.689 L2196.43 138.412 L2200.95 138.412 L2189.56 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2208.24 160.402 L2215.88 160.402 L2215.88 134.037 L2207.57 135.703 L2207.57 131.444 L2215.83 129.778 L2220.51 129.778 L2220.51 160.402 L2228.14 160.402 L2228.14 164.338 L2208.24 164.338 L2208.24 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@df data histogram(:Class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE6vYINcO94N"
      },
      "source": [
        "There are of course other types of plots you could make. Let's try to make plot showing ```mean_compactness``` and ```mean_area``` against each other. Also try to make a density plot or histogram of the column of your choosing.\n",
        "\n",
        "Hint:\n",
        "- scatterplot: ```scatter()```\n",
        "- lineplot: ```plot()```\n",
        "- densityplot: ```density()```\n",
        "- histogram: ```histogram()```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoVxXYeGPbqv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWDM1okYZ6QK"
      },
      "source": [
        "### Let's do some modelling\n",
        "\n",
        "There are many algorithms available in Julia, which makes it a great language to do modelling in. However, it can seem the task very daunting, as we don't really know where to start. Luckily, there is a framework for that! Similarly to ```Plots```, the ```MLJ``` module is a framework that provides a toolbox and interface for performig a specific task, in this case machine learning. ```MLJ``` has a large library of algorithms that can be used in the MLJ workflow. It also includes the possibility of preprocessing data (e.g., scaling), or creating pipelines and model optimalisation approaches (e.g., training and evaluating a model using a nested CV approach). \n",
        "\n",
        "Let's first use ```unpack``` to select the X and y variables. We drop ID, but select all other features. For this we use the ```select!``` command. The ! means that the call is in place, so we don't have to explicitely define a new parameter (or rebind the result to X).\n",
        "\n",
        "We can also just simply call ```y,X = unpack(data, ==(:Class),!=(:ID)``` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Um-SivJ3bQ3t"
      },
      "outputs": [],
      "source": [
        "y,X = unpack(data, ==(:Class))\n",
        "select!(X,Not(:ID));\n",
        "\n",
        "\n",
        "y = coerce(y,OrderedFactor);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXc6Kyp8J4r"
      },
      "source": [
        "We then use a StandardScaler, so that all means are 0, and all standard deviations are 1. For this we use ```Standardizer``` from the ```MLJModels``` module. There are some things going on:\n",
        "\n",
        "- ```@load``` is a call from the MLJ module, which is used to load in models from other packages (we will use this later on also for ```XGBoost``` and ```MLJLinearModels```. We define the model we want to use, and we define the package where this model is found.\n",
        "\n",
        "- We instantiate a standardiser (much like in Scikit-Learn)\n",
        "\n",
        "- We then define a ```machine```, which is an object where a model and hyperparameters are stored in.\n",
        "\n",
        "- We use ```fit!``` to fit the machine (in place), and then transform (from the MLJ package) to transform the data to the standardized data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YEI5hcy7rKz",
        "outputId": "e9e43b22-d838-49e1-dd06-3303d32e5422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Training machine(Standardizer(features = Symbol[], …), …).\n",
            "└ @ MLJBase /root/.julia/packages/MLJBase/6ooqv/src/machines.jl:496\n"
          ]
        }
      ],
      "source": [
        "Standardizer = (@load Standardizer pkg=MLJModels verbosity=0)\n",
        "stand1 = Standardizer();\n",
        "\n",
        "mach_standardiser = machine(stand1,X)\n",
        "\n",
        "X_transformed = MLJ.transform(fit!(mach_standardiser),X);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train and evaluate some models now. We want to predict y (class) using the standardised features. For ease, I already let you install XGBoost and MLJLinearModels. But of course, there are many more modules you can use (think about models such as Random Forests, Support Vector Machine, or your favourite Bayesian models).\n",
        "\n",
        "Let's load in these two types of models, similar to the standardiser."
      ],
      "metadata": {
        "id": "NSlyP5V2Ywo-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "8lEY7Zuh9mTm"
      },
      "outputs": [],
      "source": [
        "LR = (@load LogisticClassifier pkg=MLJLinearModels verbosity=0)\n",
        "lr = LR();\n",
        "XGB = (@load XGBoostClassifier pkg=XGBoost verbosity = 0)\n",
        "xgb = XGB();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next: we might want to optimize the hyperparameters in the model. For this, we can use the ```TunedModel``` function, and we can define some ranges for the hyperparameter we want to tune.\n",
        "\n",
        "For example, for the Logistic Classifier, we can tune ```lambda```, which is the penalty, as used by LASSO."
      ],
      "metadata": {
        "id": "H2BDz59eZNKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range_lr = range(lr,:lambda,values = [0.001,0.01,0.1,1,10])\n",
        "tm_lr = TunedModel(\n",
        "    model = lr,\n",
        "    range = range_lr,\n",
        "    tuning = Grid(),\n",
        "    resampling = StratifiedCV(nfolds = 5),\n",
        "    measure=accuracy\n",
        ");"
      ],
      "metadata": {
        "id": "y1UrBQ8LZmSU"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then define a machine, and use this machine for hyperparameter evaluation.\n",
        "\n",
        "Note that we define a ```StratifiedCV``` call twice (once in the ```TunedModel```, and once in the ```evaluate``` call, meaning that his approach is a nested cross-validation approach"
      ],
      "metadata": {
        "id": "Pxh8j87kbfEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = machine(tm_lr,X_transformed,y)\n",
        "e = evaluate!(m,resampling = StratifiedCV(nfolds = 5),measure = [accuracy,recall,npv,ppv,specificity])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuM0g0I0bcsA",
        "outputId": "767b154a-4b83-4ff2-9b7b-7df14bdb7017"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33mEvaluating over 5 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PerformanceEvaluation object with these fields:\n",
              "  measure, operation, measurement, per_fold,\n",
              "  per_observation, fitted_params_per_fold,\n",
              "  report_per_fold, train_test_rows\n",
              "Extract:\n",
              "┌──────────────────────────┬──────────────┬─────────────┬─────────┬─────────────\n",
              "│\u001b[22m measure                  \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold  \u001b[0m ⋯\n",
              "├──────────────────────────┼──────────────┼─────────────┼─────────┼─────────────\n",
              "│ Accuracy()               │ predict_mode │ 0.977       │ 0.00772 │ [0.982, 0. ⋯\n",
              "│ TruePositiveRate(        │ predict_mode │ 0.953       │ 0.0323  │ [0.977, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ NegativePredictiveValue( │ predict_mode │ 0.973       │ 0.0183  │ [0.986, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ Precision(               │ predict_mode │ 0.986       │ 0.0127  │ [0.977, 1. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ TrueNegativeRate(        │ predict_mode │ 0.992       │ 0.00749 │ [0.986, 1. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "└──────────────────────────┴──────────────┴─────────────┴─────────┴─────────────\n",
              "\u001b[36m                                                                1 column omitted\u001b[0m\n"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then look at a report for each outer fold, containing the best model, the history of the models that were tried (one for each value of lambda per fold), and then a measurement for accuracy in the 5 inner folds"
      ],
      "metadata": {
        "id": "9s1xnNLWiWXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e.report_per_fold[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzu7qCmsfVt8",
        "outputId": "139cee35-24ec-4526-f85f-79169ef1b9c3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(best_model = LogisticClassifier(lambda = 0.01, …),\n",
              " best_history_entry = (model = LogisticClassifier(lambda = 0.01, …),\n",
              "                       measure = [Accuracy()],\n",
              "                       measurement = [0.9824175824175825],\n",
              "                       per_fold = [[1.0, 1.0, 0.9340659340659341, 0.978021978021978, 1.0]],),\n",
              " history = NamedTuple{(:model, :measure, :measurement, :per_fold), Tuple{MLJLinearModels.LogisticClassifier, Vector{Accuracy}, Vector{Float64}, Vector{Vector{Float64}}}}[(model = LogisticClassifier(lambda = 10.0, …), measure = [Accuracy()], measurement = [0.7362637362637363], per_fold = [[0.7032967032967032, 0.7362637362637363, 0.7912087912087912, 0.7142857142857143, 0.7362637362637363]]), (model = LogisticClassifier(lambda = 0.01, …), measure = [Accuracy()], measurement = [0.9824175824175825], per_fold = [[1.0, 1.0, 0.9340659340659341, 0.978021978021978, 1.0]]), (model = LogisticClassifier(lambda = 1.0, …), measure = [Accuracy()], measurement = [0.9384615384615385], per_fold = [[0.945054945054945, 0.978021978021978, 0.9120879120879121, 0.9230769230769231, 0.9340659340659341]]), (model = LogisticClassifier(lambda = 0.001, …), measure = [Accuracy()], measurement = [0.9780219780219781], per_fold = [[1.0, 0.989010989010989, 0.9230769230769231, 0.978021978021978, 1.0]]), (model = LogisticClassifier(lambda = 0.1, …), measure = [Accuracy()], measurement = [0.964835164835165], per_fold = [[0.967032967032967, 0.989010989010989, 0.9340659340659341, 0.967032967032967, 0.967032967032967]])],\n",
              " best_report = (),\n",
              " plotting = (parameter_names = [\"lambda\"],\n",
              "             parameter_scales = [:none],\n",
              "             parameter_values = Any[10.0; 0.01; … ; 0.001; 0.1;;],\n",
              "             measurements = [0.7362637362637363, 0.9824175824175825, 0.9384615384615385, 0.9780219780219781, 0.964835164835165],),)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.report_per_fold[1].history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BojAkiHPfYjO",
        "outputId": "c723941e-152d-4568-de4c-cbd03caec6cb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5-element Vector{NamedTuple{(:model, :measure, :measurement, :per_fold), Tuple{MLJLinearModels.LogisticClassifier, Vector{Accuracy}, Vector{Float64}, Vector{Vector{Float64}}}}}:\n",
              " (model = LogisticClassifier(lambda = 10.0, …), measure = [Accuracy()], measurement = [0.7362637362637363], per_fold = [[0.7032967032967032, 0.7362637362637363, 0.7912087912087912, 0.7142857142857143, 0.7362637362637363]])\n",
              " (model = LogisticClassifier(lambda = 0.01, …), measure = [Accuracy()], measurement = [0.9824175824175825], per_fold = [[1.0, 1.0, 0.9340659340659341, 0.978021978021978, 1.0]])\n",
              " (model = LogisticClassifier(lambda = 1.0, …), measure = [Accuracy()], measurement = [0.9384615384615385], per_fold = [[0.945054945054945, 0.978021978021978, 0.9120879120879121, 0.9230769230769231, 0.9340659340659341]])\n",
              " (model = LogisticClassifier(lambda = 0.001, …), measure = [Accuracy()], measurement = [0.9780219780219781], per_fold = [[1.0, 0.989010989010989, 0.9230769230769231, 0.978021978021978, 1.0]])\n",
              " (model = LogisticClassifier(lambda = 0.1, …), measure = [Accuracy()], measurement = [0.964835164835165], per_fold = [[0.967032967032967, 0.989010989010989, 0.9340659340659341, 0.967032967032967, 0.967032967032967]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already get some pretty good results! Let's see if we can outperform Logistic Regression with LASSO using XGBoost.\n",
        "\n",
        "Here we also use the tuning parameter, which defines which hyperoptimization search is used. We can use ```Grid()``` for this, but considering the time this can take, we rather use ```RandomSearch()```. In this case, we decided to tune four different hyperparameters."
      ],
      "metadata": {
        "id": "ClCCtlUUcWXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1_xgb = range(xgb,:max_depth,lower=1,upper=10)\n",
        "r2_xgb = range(xgb,:num_round,lower=10, upper=150)\n",
        "r3_xgb = range(xgb,:gamma,lower = 0.1,upper = 0.9)\n",
        "r4_xgb = range(xgb,:eta,lower = 0.01,upper = 0.2)\n",
        "\n",
        "tm_xgb = TunedModel(\n",
        "    model=xgb,\n",
        "    resampling=StratifiedCV(nfolds = 5),\n",
        "    measure=accuracy,\n",
        "    ranges=[r1_xgb,r2_xgb,r3_xgb,r4_xgb],\n",
        "    tuning=RandomSearch()\n",
        ");\n",
        "\n"
      ],
      "metadata": {
        "id": "dFczKCOnb72d"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = machine(tm_xgb, X_transformed, y)\n",
        "e = evaluate!(m,resampling=StratifiedCV(nfolds=5),measure=[accuracy,recall,npv,ppv,specificity], verbosity=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXFa8LTcc-pb",
        "outputId": "6355ca2b-6abd-455f-873a-ab8f4f619eb5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PerformanceEvaluation object with these fields:\n",
              "  measure, operation, measurement, per_fold,\n",
              "  per_observation, fitted_params_per_fold,\n",
              "  report_per_fold, train_test_rows\n",
              "Extract:\n",
              "┌──────────────────────────┬──────────────┬─────────────┬─────────┬─────────────\n",
              "│\u001b[22m measure                  \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold  \u001b[0m ⋯\n",
              "├──────────────────────────┼──────────────┼─────────────┼─────────┼─────────────\n",
              "│ Accuracy()               │ predict_mode │ 0.965       │ 0.0161  │ [0.965, 0. ⋯\n",
              "│ TruePositiveRate(        │ predict_mode │ 0.948       │ 0.0197  │ [0.953, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ NegativePredictiveValue( │ predict_mode │ 0.969       │ 0.0111  │ [0.972, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ Precision(               │ predict_mode │ 0.958       │ 0.0322  │ [0.953, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ TrueNegativeRate(        │ predict_mode │ 0.975       │ 0.0205  │ [0.972, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "└──────────────────────────┴──────────────┴─────────────┴─────────┴─────────────\n",
              "\u001b[36m                                                                1 column omitted\u001b[0m\n"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = machine(tm_xgb, X_transformed, y)\n",
        "e = evaluate!(m,resampling=StratifiedCV(nfolds=5),measure=[accuracy,recall,npv,ppv,specificity], verbosity=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztvqBjVRlcSv",
        "outputId": "7745ac86-fcef-4e44-b0f4-3add64d5f0ae"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PerformanceEvaluation object with these fields:\n",
              "  measure, operation, measurement, per_fold,\n",
              "  per_observation, fitted_params_per_fold,\n",
              "  report_per_fold, train_test_rows\n",
              "Extract:\n",
              "┌──────────────────────────┬──────────────┬─────────────┬─────────┬─────────────\n",
              "│\u001b[22m measure                  \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold  \u001b[0m ⋯\n",
              "├──────────────────────────┼──────────────┼─────────────┼─────────┼─────────────\n",
              "│ Accuracy()               │ predict_mode │ 0.963       │ 0.0166  │ [0.965, 0. ⋯\n",
              "│ TruePositiveRate(        │ predict_mode │ 0.943       │ 0.0268  │ [0.953, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ NegativePredictiveValue( │ predict_mode │ 0.967       │ 0.015   │ [0.972, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ Precision(               │ predict_mode │ 0.957       │ 0.0249  │ [0.953, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "│ TrueNegativeRate(        │ predict_mode │ 0.975       │ 0.0151  │ [0.972, 0. ⋯\n",
              "│   rev = nothing)         │              │             │         │            ⋯\n",
              "└──────────────────────────┴──────────────┴─────────────┴─────────┴─────────────\n",
              "\u001b[36m                                                                1 column omitted\u001b[0m\n"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can look at each fold, and get a report, including the tuning history (which models were tried in this outer fold)."
      ],
      "metadata": {
        "id": "japX67ISjzwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e.report_per_fold[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRPEBvthfx_e",
        "outputId": "5755cc32-33f5-4663-b32e-f597530a4ff4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(best_model = XGBoostClassifier(num_round = 50, …),\n",
              " best_history_entry = (model = XGBoostClassifier(num_round = 50, …),\n",
              "                       measure = [Accuracy()],\n",
              "                       measurement = [0.9692307692307693],\n",
              "                       per_fold = [[0.9560439560439561, 0.989010989010989, 0.945054945054945, 0.9560439560439561, 1.0]],),\n",
              " history = NamedTuple{(:model, :measure, :measurement, :per_fold), Tuple{MLJXGBoostInterface.XGBoostClassifier, Vector{Accuracy}, Vector{Float64}, Vector{Vector{Float64}}}}[(model = XGBoostClassifier(num_round = 130, …), measure = [Accuracy()], measurement = [0.9604395604395604], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 0.978021978021978]]), (model = XGBoostClassifier(num_round = 96, …), measure = [Accuracy()], measurement = [0.9648351648351647], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 1.0]]), (model = XGBoostClassifier(num_round = 102, …), measure = [Accuracy()], measurement = [0.9670329670329672], per_fold = [[0.9560439560439561, 0.989010989010989, 0.945054945054945, 0.9560439560439561, 0.989010989010989]]), (model = XGBoostClassifier(num_round = 79, …), measure = [Accuracy()], measurement = [0.9582417582417582], per_fold = [[0.945054945054945, 0.967032967032967, 0.945054945054945, 0.9560439560439561, 0.978021978021978]]), (model = XGBoostClassifier(num_round = 50, …), measure = [Accuracy()], measurement = [0.9692307692307693], per_fold = [[0.9560439560439561, 0.989010989010989, 0.945054945054945, 0.9560439560439561, 1.0]]), (model = XGBoostClassifier(num_round = 63, …), measure = [Accuracy()], measurement = [0.9406593406593406], per_fold = [[0.945054945054945, 0.945054945054945, 0.9340659340659341, 0.945054945054945, 0.9340659340659341]]), (model = XGBoostClassifier(num_round = 21, …), measure = [Accuracy()], measurement = [0.9318681318681319], per_fold = [[0.945054945054945, 0.9560439560439561, 0.9010989010989011, 0.9230769230769231, 0.9340659340659341]]), (model = XGBoostClassifier(num_round = 37, …), measure = [Accuracy()], measurement = [0.9604395604395604], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 0.978021978021978]]), (model = XGBoostClassifier(num_round = 13, …), measure = [Accuracy()], measurement = [0.9472527472527472], per_fold = [[0.9560439560439561, 0.945054945054945, 0.9340659340659341, 0.9560439560439561, 0.945054945054945]]), (model = XGBoostClassifier(num_round = 91, …), measure = [Accuracy()], measurement = [0.9428571428571428], per_fold = [[0.945054945054945, 0.978021978021978, 0.9010989010989011, 0.945054945054945, 0.945054945054945]])],\n",
              " best_report = (feature_importances = 27-element Vector{XGBoost.FeatureImportance}:\n",
              "Gain      Coverage  Frequency  Feature\n",
              "0.3969    0.1629    0.0764     worst_concave_points\n",
              "0.2399    0.1032    0.0486     mean_concave_points\n",
              "0.0973    0.0959    0.0556     worst_perimeter\n",
              "0.0918    0.1539    0.1458     worst_area\n",
              "0.0696    0.1119    0.1632     worst_texture\n",
              "0.0279    0.0511    0.0660     worst_concavity\n",
              "0.0181    0.0426    0.0868     mean_texture\n",
              "0.0116    0.0628    0.0590     area_error\n",
              "0.0111    0.0345    0.0208     worst_adius\n",
              "0.0067    0.0415    0.0278     mean_area\n",
              "0.0065    0.0130    0.0556     worst_smoothness\n",
              "0.0045    0.0045    0.0278     compactness_error\n",
              "0.0034    0.0037    0.0104     symmetry_error\n",
              "0.0028    0.0131    0.0382     mean_smoothness\n",
              "0.0015    0.0068    0.0035     concavity_error\n",
              "0.0015    0.0050    0.0243     mean_fractal_dimension\n",
              "0.0015    0.0364    0.0174     smoothness_error\n",
              "0.0012    0.0019    0.0069     mean_symmetry\n",
              "0.0011    0.0189    0.0174     worst_symmetry\n",
              "0.0010    0.0018    0.0069     mean_radius\n",
              "0.0010    0.0121    0.0104     fractal_dimension error\n",
              "0.0008    0.0005    0.0035     mean_compactness\n",
              "0.0007    0.0066    0.0035     mean_concavity\n",
              "0.0005    0.0033    0.0104     worst_compactness\n",
              "0.0005    0.0010    0.0069     worst_fractal_dimension\n",
              "0.0002    0.0010    0.0035     radius_error\n",
              "0.0002    0.0100    0.0035     concave_points_error\n",
              ",),\n",
              " plotting = (parameter_names = [\"max_depth\", \"eta\", \"gamma\", \"num_round\"],\n",
              "             parameter_scales = [:linear, :linear, :linear, :linear],\n",
              "             parameter_values = Any[4 0.08572808106781203 0.4842069182174844 130; 9 0.14359993920120714 0.18409837648790559 96; … ; 5 0.18209584956803693 0.5836023980664035 13; 1 0.04014989149917337 0.5701406742234464 91],\n",
              "             measurements = [0.9604395604395604, 0.9648351648351647, 0.9670329670329672, 0.9582417582417582, 0.9692307692307693, 0.9406593406593406, 0.9318681318681319, 0.9604395604395604, 0.9472527472527472, 0.9428571428571428],),)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "e.report_per_fold[1].history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsIRfSDahGi_",
        "outputId": "93be7b2b-9b40-4b10-e5a6-16ecf9d30cb6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10-element Vector{NamedTuple{(:model, :measure, :measurement, :per_fold), Tuple{MLJXGBoostInterface.XGBoostClassifier, Vector{Accuracy}, Vector{Float64}, Vector{Vector{Float64}}}}}:\n",
              " (model = XGBoostClassifier(num_round = 130, …), measure = [Accuracy()], measurement = [0.9604395604395604], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 0.978021978021978]])\n",
              " (model = XGBoostClassifier(num_round = 96, …), measure = [Accuracy()], measurement = [0.9648351648351647], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 1.0]])\n",
              " (model = XGBoostClassifier(num_round = 102, …), measure = [Accuracy()], measurement = [0.9670329670329672], per_fold = [[0.9560439560439561, 0.989010989010989, 0.945054945054945, 0.9560439560439561, 0.989010989010989]])\n",
              " (model = XGBoostClassifier(num_round = 79, …), measure = [Accuracy()], measurement = [0.9582417582417582], per_fold = [[0.945054945054945, 0.967032967032967, 0.945054945054945, 0.9560439560439561, 0.978021978021978]])\n",
              " (model = XGBoostClassifier(num_round = 50, …), measure = [Accuracy()], measurement = [0.9692307692307693], per_fold = [[0.9560439560439561, 0.989010989010989, 0.945054945054945, 0.9560439560439561, 1.0]])\n",
              " (model = XGBoostClassifier(num_round = 63, …), measure = [Accuracy()], measurement = [0.9406593406593406], per_fold = [[0.945054945054945, 0.945054945054945, 0.9340659340659341, 0.945054945054945, 0.9340659340659341]])\n",
              " (model = XGBoostClassifier(num_round = 21, …), measure = [Accuracy()], measurement = [0.9318681318681319], per_fold = [[0.945054945054945, 0.9560439560439561, 0.9010989010989011, 0.9230769230769231, 0.9340659340659341]])\n",
              " (model = XGBoostClassifier(num_round = 37, …), measure = [Accuracy()], measurement = [0.9604395604395604], per_fold = [[0.945054945054945, 0.978021978021978, 0.945054945054945, 0.9560439560439561, 0.978021978021978]])\n",
              " (model = XGBoostClassifier(num_round = 13, …), measure = [Accuracy()], measurement = [0.9472527472527472], per_fold = [[0.9560439560439561, 0.945054945054945, 0.9340659340659341, 0.9560439560439561, 0.945054945054945]])\n",
              " (model = XGBoostClassifier(num_round = 91, …), measure = [Accuracy()], measurement = [0.9428571428571428], per_fold = [[0.945054945054945, 0.978021978021978, 0.9010989010989011, 0.945054945054945, 0.945054945054945]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.report_per_fold[1].history[1].model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_P1XuiokGf-",
        "outputId": "ee5e5cf1-2b9c-41da-b68d-aac06c5a4a05"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBoostClassifier(\n",
              "  num_round = 130, \n",
              "  booster = \"gbtree\", \n",
              "  disable_default_eval_metric = 0, \n",
              "  eta = 0.08572808106781203, \n",
              "  gamma = 0.4842069182174844, \n",
              "  max_depth = 4, \n",
              "  min_child_weight = 1.0, \n",
              "  max_delta_step = 0.0, \n",
              "  subsample = 1.0, \n",
              "  colsample_bytree = 1.0, \n",
              "  colsample_bylevel = 1.0, \n",
              "  lambda = 1.0, \n",
              "  alpha = 0.0, \n",
              "  tree_method = \"auto\", \n",
              "  sketch_eps = 0.03, \n",
              "  scale_pos_weight = 1.0, \n",
              "  updater = \"auto\", \n",
              "  refresh_leaf = 1, \n",
              "  process_type = \"default\", \n",
              "  grow_policy = \"depthwise\", \n",
              "  max_leaves = 0, \n",
              "  max_bin = 256, \n",
              "  predictor = \"cpu_predictor\", \n",
              "  sample_type = \"uniform\", \n",
              "  normalize_type = \"tree\", \n",
              "  rate_drop = 0.0, \n",
              "  one_drop = 0, \n",
              "  skip_drop = 0.0, \n",
              "  feature_selector = \"cyclic\", \n",
              "  top_k = 0, \n",
              "  tweedie_variance_power = 1.5, \n",
              "  objective = \"automatic\", \n",
              "  base_score = 0.5, \n",
              "  eval_metric = \"mlogloss\", \n",
              "  seed = 0, \n",
              "  nthread = 1)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go ahead and try different types of models! Use ```models(matching(X_transformed, y))``` to find out which models from what modules can actually be used on this data! Then use ```Pkg.add()``` to install the module, and ```@load``` to load the model into existence"
      ],
      "metadata": {
        "id": "eAfGhv9hdnlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models(matching(X_transformed, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgm4_oz5dIUP",
        "outputId": "bb60cb41-cd74-43cc-e62f-710bb4493ce5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n",
              " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
              " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
              " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
              " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
              " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
              " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
              " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
              " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
              " (name = DSADDetector, package_name = OutlierDetectionNetworks, ... )\n",
              " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
              " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
              " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
              " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
              " ⋮\n",
              " (name = RandomForestClassifier, package_name = BetaML, ... )\n",
              " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
              " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
              " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
              " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
              " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
              " (name = SVC, package_name = LIBSVM, ... )\n",
              " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
              " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
              " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
              " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
              " (name = XGBoostClassifier, package_name = XGBoost, ... )"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLHTd8Ovd0GS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}